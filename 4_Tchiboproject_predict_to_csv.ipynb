{"cells":[{"cell_type":"markdown","source":["## Notebook overview:\n","- In this notebook we load a csv files with links of pictures and tag them\n","- First we install the TFOD API\n","- Then we load the csv file out of csv directory into a data frame and manipulate them for our needs\n","- After that we create a list out of our Panda Series with links\n","- Then we need to define a function for loading the pictures from an url\n","- We predict each url(picture) and write the prediction to the dataframe\n","- Finally we can save the datframe in the csv format"],"metadata":{"id":"dzrllA9iqztk"}},{"cell_type":"code","source":["#connect to our drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"4XabFQRir5Io","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645993804068,"user_tz":-60,"elapsed":24609,"user":{"displayName":"Felix Steppack","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14866878991453271329"}},"outputId":"31808b9f-29b1-4608-d920-76e6030583f0"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"xTvBGgDG_X-q"},"source":["## Cloning TFOD 2.0 Github needed for inferencing"]},{"cell_type":"code","source":["cd /content/"],"metadata":{"id":"H4Myltvzr_Aq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645993843008,"user_tz":-60,"elapsed":331,"user":{"displayName":"Felix Steppack","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14866878991453271329"}},"outputId":"1a36f68e-a372-4171-adc1-5d5f49b1b75a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15065,"status":"ok","timestamp":1645993858372,"user":{"displayName":"Felix Steppack","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14866878991453271329"},"user_tz":-60},"id":"1HoDwEEr_cT8","outputId":"b21fa290-e618-4a20-b331-42bd658aa6fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'models'...\n","remote: Enumerating objects: 69341, done.\u001b[K\n","remote: Total 69341 (delta 0), reused 0 (delta 0), pack-reused 69341\u001b[K\n","Receiving objects: 100% (69341/69341), 577.37 MiB | 47.99 MiB/s, done.\n","Resolving deltas: 100% (48882/48882), done.\n"]}],"source":["!git clone https://github.com/tensorflow/models.git"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1645993858373,"user":{"displayName":"Felix Steppack","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14866878991453271329"},"user_tz":-60},"id":"2bHshZcx_fst","outputId":"ff37d3b8-d9b3-4250-8959-600ac36eb031"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/models/research\n"]}],"source":["cd /content/models/research"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"6CYb5Jzs_f0N","executionInfo":{"status":"ok","timestamp":1645993858374,"user_tz":-60,"elapsed":8,"user":{"displayName":"Felix Steppack","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14866878991453271329"}}},"outputs":[],"source":["!protoc object_detection/protos/*.proto --python_out=."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"BlQci1Vv_f3o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645993859444,"user_tz":-60,"elapsed":1076,"user":{"displayName":"Felix Steppack","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14866878991453271329"}},"outputId":"f50fc8f7-1212-49b6-bb12-ecaf8f30b454"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'cocoapi'...\n","remote: Enumerating objects: 975, done.\u001b[K\n","remote: Total 975 (delta 0), reused 0 (delta 0), pack-reused 975\u001b[K\n","Receiving objects: 100% (975/975), 11.72 MiB | 30.47 MiB/s, done.\n","Resolving deltas: 100% (576/576), done.\n"]}],"source":["!git clone https://github.com/cocodataset/cocoapi.git"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1645993859445,"user":{"displayName":"Felix Steppack","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14866878991453271329"},"user_tz":-60},"id":"63mABW2s_f6p","outputId":"a7ccab3d-7560-4aeb-d3ef-e6118b6308bc"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/models/research/cocoapi/PythonAPI\n"]}],"source":["cd cocoapi/PythonAPI"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"fSuw029V_f9l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645993865080,"user_tz":-60,"elapsed":5638,"user":{"displayName":"Felix Steppack","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14866878991453271329"}},"outputId":"7e5077e3-c6b5-4c99-92ed-29937a3c0179"},"outputs":[{"output_type":"stream","name":"stdout","text":["python setup.py build_ext --inplace\n","running build_ext\n","cythoning pycocotools/_mask.pyx to pycocotools/_mask.c\n","/usr/local/lib/python3.7/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/models/research/cocoapi/PythonAPI/pycocotools/_mask.pyx\n","  tree = Parsing.p_module(s, pxd, full_module_name)\n","building 'pycocotools._mask' extension\n","creating build\n","creating build/common\n","creating build/temp.linux-x86_64-3.7\n","creating build/temp.linux-x86_64-3.7/pycocotools\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c ../common/maskApi.c -o build/temp.linux-x86_64-3.7/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n","       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n","       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n","                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n","   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n","   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n","                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:167:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n","   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:167:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n","   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n","                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:212:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n","       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:212:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n","       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n","                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:220:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n","   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:220:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n","   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n","                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:228:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n","     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:228:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n","     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n","                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToBbox\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:141:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kxp\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n","       if(j%2==0) xp=x; else if\u001b[01;35m\u001b[K(\u001b[m\u001b[Kxp<x) { ys=0; ye=h-1; }\n","                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n","creating build/lib.linux-x86_64-3.7\n","creating build/lib.linux-x86_64-3.7/pycocotools\n","x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/../common/maskApi.o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -o build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so\n","copying build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so -> pycocotools\n","rm -rf build\n"]}],"source":["!make"]},{"cell_type":"markdown","metadata":{"id":"QixeQd1l_1ID"},"source":["### Install the Object Detection API"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1645993865081,"user":{"displayName":"Felix Steppack","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14866878991453271329"},"user_tz":-60},"id":"aGaD1HZy_gAh","outputId":"8bbad8bd-2ff3-4107-b8fd-07561e98d4ea"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/models/research\n"]}],"source":["cd /content/models/research"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39692,"status":"ok","timestamp":1645993904764,"user":{"displayName":"Felix Steppack","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14866878991453271329"},"user_tz":-60},"id":"NB5XO-BG_gDU","outputId":"1e9cddc6-b5ba-4335-a883-1a177c2af75b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Processing /content/models/research\n","\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n","Collecting avro-python3\n","  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n","Collecting apache-beam\n","  Downloading apache_beam-2.36.0-cp37-cp37m-manylinux2010_x86_64.whl (10.1 MB)\n","\u001b[K     |████████████████████████████████| 10.1 MB 8.6 MB/s \n","\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.28)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n","Collecting tf-slim\n","  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n","\u001b[K     |████████████████████████████████| 352 kB 77.6 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.4)\n","Collecting lvis\n","  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.3.5)\n","Collecting tf-models-official>=2.5.1\n","  Downloading tf_models_official-2.8.0-py2.py3-none-any.whl (2.2 MB)\n","\u001b[K     |████████████████████████████████| 2.2 MB 66.6 MB/s \n","\u001b[?25hCollecting tensorflow_io\n","  Downloading tensorflow_io-0.24.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.4 MB)\n","\u001b[K     |████████████████████████████████| 23.4 MB 680 kB/s \n","\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.8.0)\n","Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 64.9 MB/s \n","\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n","Collecting opencv-python-headless\n","  Downloading opencv_python_headless-4.5.5.62-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.7 MB)\n","\u001b[K     |████████████████████████████████| 47.7 MB 1.1 MB/s \n","\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n","  Downloading tensorflow_model_optimization-0.7.1-py2.py3-none-any.whl (234 kB)\n","\u001b[K     |████████████████████████████████| 234 kB 78.3 MB/s \n","\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n","Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n","Collecting tensorflow-text~=2.8.0\n","  Downloading tensorflow_text-2.8.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n","\u001b[K     |████████████████████████████████| 4.9 MB 68.4 MB/s \n","\u001b[?25hCollecting pyyaml<6.0,>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 73.2 MB/s \n","\u001b[?25hCollecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 2.0 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n","Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n","Requirement already satisfied: tensorflow~=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.8.0)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.21.5)\n","Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n","Collecting py-cpuinfo>=3.3.0\n","  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n","\u001b[K     |████████████████████████████████| 99 kB 9.0 MB/s \n","\u001b[?25hCollecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 65.6 MB/s \n","\u001b[?25hRequirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.10)\n","Collecting sacrebleu\n","  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n","\u001b[K     |████████████████████████████████| 90 kB 9.2 MB/s \n","\u001b[?25hRequirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n","Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n","Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.26.3)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2018.9)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.54.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.10.8)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.0.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.62.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.7)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.8.0)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.5.3)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.13.3)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n","Collecting tf-estimator-nightly==2.8.0.dev2021122109\n","  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n","\u001b[K     |████████████████████████████████| 462 kB 75.6 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.10.0.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (13.0.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.43.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.24.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.6)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (4.11.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.7.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.6)\n","Collecting cloudpickle<3,>=2.0.0\n","  Downloading cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n","Collecting orjson<4.0\n","  Downloading orjson-3.6.7-cp37-cp37m-manylinux_2_24_x86_64.whl (255 kB)\n","\u001b[K     |████████████████████████████████| 255 kB 74.3 MB/s \n","\u001b[?25hCollecting pymongo<4.0.0,>=3.8.0\n","  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n","\u001b[K     |████████████████████████████████| 508 kB 72.5 MB/s \n","\u001b[?25hCollecting fastavro<2,>=0.21.4\n","  Downloading fastavro-1.4.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n","\u001b[K     |████████████████████████████████| 2.3 MB 69.9 MB/s \n","\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n","  Downloading hdfs-2.6.0-py3-none-any.whl (33 kB)\n","Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n","Collecting dill<0.3.2,>=0.3.1.1\n","  Downloading dill-0.3.1.1.tar.gz (151 kB)\n","\u001b[K     |████████████████████████████████| 151 kB 75.7 MB/s \n","\u001b[?25hRequirement already satisfied: pyarrow<7.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (6.0.1)\n","Collecting proto-plus<2,>=1.7.1\n","  Downloading proto_plus-1.20.3-py3-none-any.whl (46 kB)\n","\u001b[K     |████████████████████████████████| 46 kB 3.4 MB/s \n","\u001b[?25hRequirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n","Collecting requests<3.0.0dev,>=2.18.0\n","  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n","\u001b[?25hRequirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n","Collecting protobuf>=3.12.0\n","  Downloading protobuf-3.19.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 64.0 MB/s \n","\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.12)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.3.2)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2019.12.20)\n","Collecting portalocker\n","  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n","Collecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.4.0)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.4.0)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.6.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.16.0)\n","Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n","Building wheels for collected packages: object-detection, py-cpuinfo, dill, avro-python3, seqeval\n","  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1686356 sha256=0d335763f19b8ea19d44d20df9456a99dcc26b559cb3cb1163018fad97f0e002\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-nlijxcrj/wheels/fa/a4/d2/e9a5057e414fd46c8e543d2706cd836d64e1fcd9eccceb2329\n","  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=be14280924bc68bd414b5734c77bd72ee6d8b61e9ff76e5093315947eb2e66ce\n","  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n","  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=4087e3c1a5a901e5483da74dd20a1831af5459cedf1c7f3fbe917300853efe41\n","  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n","  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=b5d797441c3773a513966e96af89fae6c23de77a0dc9e74b81203072df8171e3\n","  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=246cf289c53eb02b0ad995f1e2bcba8f90d354804bd933cc8d96d305895bf9e1\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built object-detection py-cpuinfo dill avro-python3 seqeval\n","Installing collected packages: requests, protobuf, tf-estimator-nightly, portalocker, dill, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, py-cpuinfo, proto-plus, orjson, opencv-python-headless, hdfs, fastavro, cloudpickle, tf-models-official, tensorflow-io, lvis, avro-python3, apache-beam, object-detection\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.17.3\n","    Uninstalling protobuf-3.17.3:\n","      Successfully uninstalled protobuf-3.17.3\n","  Attempting uninstall: dill\n","    Found existing installation: dill 0.3.4\n","    Uninstalling dill-0.3.4:\n","      Successfully uninstalled dill-0.3.4\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: pymongo\n","    Found existing installation: pymongo 4.0.1\n","    Uninstalling pymongo-4.0.1:\n","      Successfully uninstalled pymongo-4.0.1\n","  Attempting uninstall: cloudpickle\n","    Found existing installation: cloudpickle 1.3.0\n","    Uninstalling cloudpickle-1.3.0:\n","      Successfully uninstalled cloudpickle-1.3.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n","gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed apache-beam-2.36.0 avro-python3-1.10.2 cloudpickle-2.0.0 colorama-0.4.4 dill-0.3.1.1 fastavro-1.4.9 hdfs-2.6.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.5.62 orjson-3.6.7 portalocker-2.4.0 proto-plus-1.20.3 protobuf-3.19.4 py-cpuinfo-8.0.0 pymongo-3.12.3 pyyaml-5.4.1 requests-2.27.1 sacrebleu-2.0.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.16.1 tensorflow-io-0.24.0 tensorflow-model-optimization-0.7.1 tensorflow-text-2.8.1 tf-estimator-nightly-2.8.0.dev2021122109 tf-models-official-2.8.0 tf-slim-1.1.0\n"]}],"source":["!cp object_detection/packages/tf2/setup.py .\n","!python -m pip install ."]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37676,"status":"ok","timestamp":1645993942435,"user":{"displayName":"Felix Steppack","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14866878991453271329"},"user_tz":-60},"id":"TfMHkjwK_gGI","outputId":"3c84683b-774e-493a-9422-9ad02d69bdff"},"outputs":[{"output_type":"stream","name":"stdout","text":["2022-02-27 20:31:49.239754: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","Running tests under Python 3.7.12: /usr/bin/python3\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","W0227 20:31:49.705248 140629575182208 model_builder.py:1100] Building experimental DeepMAC meta-arch. Some features may be omitted.\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.76s\n","I0227 20:31:50.005327 140629575182208 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.76s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.59s\n","I0227 20:31:50.598864 140629575182208 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.59s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.31s\n","I0227 20:31:50.909070 140629575182208 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.31s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.28s\n","I0227 20:31:51.194521 140629575182208 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.28s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.25s\n","I0227 20:31:53.444685 140629575182208 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.25s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","I0227 20:31:53.445807 140629575182208 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n","I0227 20:31:53.475258 140629575182208 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n","I0227 20:31:53.493576 140629575182208 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n","I0227 20:31:53.512858 140629575182208 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.12s\n","I0227 20:31:53.634708 140629575182208 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.12s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.11s\n","I0227 20:31:53.749591 140629575182208 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.11s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.12s\n","I0227 20:31:53.870518 140629575182208 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.12s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.12s\n","I0227 20:31:53.989750 140629575182208 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.12s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.12s\n","I0227 20:31:54.106330 140629575182208 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.12s\n","[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n","I0227 20:31:54.139913 140629575182208 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","I0227 20:31:54.350453 140629575182208 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n","I0227 20:31:54.350651 140629575182208 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n","I0227 20:31:54.350720 140629575182208 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n","I0227 20:31:54.353724 140629575182208 efficientnet_model.py:144] round_filter input=32 output=32\n","I0227 20:31:54.373866 140629575182208 efficientnet_model.py:144] round_filter input=32 output=32\n","I0227 20:31:54.374070 140629575182208 efficientnet_model.py:144] round_filter input=16 output=16\n","I0227 20:31:54.441577 140629575182208 efficientnet_model.py:144] round_filter input=16 output=16\n","I0227 20:31:54.441773 140629575182208 efficientnet_model.py:144] round_filter input=24 output=24\n","I0227 20:31:54.624101 140629575182208 efficientnet_model.py:144] round_filter input=24 output=24\n","I0227 20:31:54.624295 140629575182208 efficientnet_model.py:144] round_filter input=40 output=40\n","I0227 20:31:54.802888 140629575182208 efficientnet_model.py:144] round_filter input=40 output=40\n","I0227 20:31:54.803102 140629575182208 efficientnet_model.py:144] round_filter input=80 output=80\n","I0227 20:31:55.100691 140629575182208 efficientnet_model.py:144] round_filter input=80 output=80\n","I0227 20:31:55.100905 140629575182208 efficientnet_model.py:144] round_filter input=112 output=112\n","I0227 20:31:55.386635 140629575182208 efficientnet_model.py:144] round_filter input=112 output=112\n","I0227 20:31:55.386833 140629575182208 efficientnet_model.py:144] round_filter input=192 output=192\n","I0227 20:31:55.973818 140629575182208 efficientnet_model.py:144] round_filter input=192 output=192\n","I0227 20:31:55.974046 140629575182208 efficientnet_model.py:144] round_filter input=320 output=320\n","I0227 20:31:56.079018 140629575182208 efficientnet_model.py:144] round_filter input=1280 output=1280\n","I0227 20:31:56.120484 140629575182208 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0227 20:31:56.186603 140629575182208 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b1\n","I0227 20:31:56.186797 140629575182208 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n","I0227 20:31:56.186865 140629575182208 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 4\n","I0227 20:31:56.188838 140629575182208 efficientnet_model.py:144] round_filter input=32 output=32\n","I0227 20:31:56.208157 140629575182208 efficientnet_model.py:144] round_filter input=32 output=32\n","I0227 20:31:56.208349 140629575182208 efficientnet_model.py:144] round_filter input=16 output=16\n","I0227 20:31:56.351038 140629575182208 efficientnet_model.py:144] round_filter input=16 output=16\n","I0227 20:31:56.351232 140629575182208 efficientnet_model.py:144] round_filter input=24 output=24\n","I0227 20:31:56.672772 140629575182208 efficientnet_model.py:144] round_filter input=24 output=24\n","I0227 20:31:56.672998 140629575182208 efficientnet_model.py:144] round_filter input=40 output=40\n","I0227 20:31:56.948864 140629575182208 efficientnet_model.py:144] round_filter input=40 output=40\n","I0227 20:31:56.949073 140629575182208 efficientnet_model.py:144] round_filter input=80 output=80\n","I0227 20:31:57.328674 140629575182208 efficientnet_model.py:144] round_filter input=80 output=80\n","I0227 20:31:57.328922 140629575182208 efficientnet_model.py:144] round_filter input=112 output=112\n","I0227 20:31:57.705467 140629575182208 efficientnet_model.py:144] round_filter input=112 output=112\n","I0227 20:31:57.705687 140629575182208 efficientnet_model.py:144] round_filter input=192 output=192\n","I0227 20:31:58.192083 140629575182208 efficientnet_model.py:144] round_filter input=192 output=192\n","I0227 20:31:58.192295 140629575182208 efficientnet_model.py:144] round_filter input=320 output=320\n","I0227 20:31:58.389851 140629575182208 efficientnet_model.py:144] round_filter input=1280 output=1280\n","I0227 20:31:58.431411 140629575182208 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0227 20:31:58.505763 140629575182208 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b2\n","I0227 20:31:58.505986 140629575182208 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n","I0227 20:31:58.506059 140629575182208 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 5\n","I0227 20:31:58.508068 140629575182208 efficientnet_model.py:144] round_filter input=32 output=32\n","I0227 20:31:58.527466 140629575182208 efficientnet_model.py:144] round_filter input=32 output=32\n","I0227 20:31:58.527671 140629575182208 efficientnet_model.py:144] round_filter input=16 output=16\n","I0227 20:31:58.669242 140629575182208 efficientnet_model.py:144] round_filter input=16 output=16\n","I0227 20:31:58.669438 140629575182208 efficientnet_model.py:144] round_filter input=24 output=24\n","I0227 20:31:58.939175 140629575182208 efficientnet_model.py:144] round_filter input=24 output=24\n","I0227 20:31:58.939372 140629575182208 efficientnet_model.py:144] round_filter input=40 output=48\n","I0227 20:31:59.216118 140629575182208 efficientnet_model.py:144] round_filter input=40 output=48\n","I0227 20:31:59.216321 140629575182208 efficientnet_model.py:144] round_filter input=80 output=88\n","I0227 20:31:59.596562 140629575182208 efficientnet_model.py:144] round_filter input=80 output=88\n","I0227 20:31:59.596791 140629575182208 efficientnet_model.py:144] round_filter input=112 output=120\n","I0227 20:31:59.988408 140629575182208 efficientnet_model.py:144] round_filter input=112 output=120\n","I0227 20:31:59.988636 140629575182208 efficientnet_model.py:144] round_filter input=192 output=208\n","I0227 20:32:00.486414 140629575182208 efficientnet_model.py:144] round_filter input=192 output=208\n","I0227 20:32:00.486627 140629575182208 efficientnet_model.py:144] round_filter input=320 output=352\n","I0227 20:32:00.696172 140629575182208 efficientnet_model.py:144] round_filter input=1280 output=1408\n","I0227 20:32:00.740493 140629575182208 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0227 20:32:00.815187 140629575182208 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b3\n","I0227 20:32:00.815679 140629575182208 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n","I0227 20:32:00.815846 140629575182208 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 6\n","I0227 20:32:00.818545 140629575182208 efficientnet_model.py:144] round_filter input=32 output=40\n","I0227 20:32:00.839568 140629575182208 efficientnet_model.py:144] round_filter input=32 output=40\n","I0227 20:32:00.839775 140629575182208 efficientnet_model.py:144] round_filter input=16 output=24\n","I0227 20:32:01.244131 140629575182208 efficientnet_model.py:144] round_filter input=16 output=24\n","I0227 20:32:01.244338 140629575182208 efficientnet_model.py:144] round_filter input=24 output=32\n","I0227 20:32:01.519789 140629575182208 efficientnet_model.py:144] round_filter input=24 output=32\n","I0227 20:32:01.520017 140629575182208 efficientnet_model.py:144] round_filter input=40 output=48\n","I0227 20:32:01.797138 140629575182208 efficientnet_model.py:144] round_filter input=40 output=48\n","I0227 20:32:01.797343 140629575182208 efficientnet_model.py:144] round_filter input=80 output=96\n","I0227 20:32:02.276585 140629575182208 efficientnet_model.py:144] round_filter input=80 output=96\n","I0227 20:32:02.276809 140629575182208 efficientnet_model.py:144] round_filter input=112 output=136\n","I0227 20:32:02.753684 140629575182208 efficientnet_model.py:144] round_filter input=112 output=136\n","I0227 20:32:02.753922 140629575182208 efficientnet_model.py:144] round_filter input=192 output=232\n","I0227 20:32:03.337488 140629575182208 efficientnet_model.py:144] round_filter input=192 output=232\n","I0227 20:32:03.337699 140629575182208 efficientnet_model.py:144] round_filter input=320 output=384\n","I0227 20:32:03.530447 140629575182208 efficientnet_model.py:144] round_filter input=1280 output=1536\n","I0227 20:32:03.571181 140629575182208 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0227 20:32:03.651515 140629575182208 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b4\n","I0227 20:32:03.651716 140629575182208 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n","I0227 20:32:03.651780 140629575182208 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n","I0227 20:32:03.653751 140629575182208 efficientnet_model.py:144] round_filter input=32 output=48\n","I0227 20:32:03.672406 140629575182208 efficientnet_model.py:144] round_filter input=32 output=48\n","I0227 20:32:03.672605 140629575182208 efficientnet_model.py:144] round_filter input=16 output=24\n","I0227 20:32:03.820271 140629575182208 efficientnet_model.py:144] round_filter input=16 output=24\n","I0227 20:32:03.820479 140629575182208 efficientnet_model.py:144] round_filter input=24 output=32\n","I0227 20:32:04.202518 140629575182208 efficientnet_model.py:144] round_filter input=24 output=32\n","I0227 20:32:04.202735 140629575182208 efficientnet_model.py:144] round_filter input=40 output=56\n","I0227 20:32:04.578601 140629575182208 efficientnet_model.py:144] round_filter input=40 output=56\n","I0227 20:32:04.578801 140629575182208 efficientnet_model.py:144] round_filter input=80 output=112\n","I0227 20:32:05.148110 140629575182208 efficientnet_model.py:144] round_filter input=80 output=112\n","I0227 20:32:05.148338 140629575182208 efficientnet_model.py:144] round_filter input=112 output=160\n","I0227 20:32:05.725177 140629575182208 efficientnet_model.py:144] round_filter input=112 output=160\n","I0227 20:32:05.725401 140629575182208 efficientnet_model.py:144] round_filter input=192 output=272\n","I0227 20:32:06.517300 140629575182208 efficientnet_model.py:144] round_filter input=192 output=272\n","I0227 20:32:06.517502 140629575182208 efficientnet_model.py:144] round_filter input=320 output=448\n","I0227 20:32:06.720347 140629575182208 efficientnet_model.py:144] round_filter input=1280 output=1792\n","I0227 20:32:06.765970 140629575182208 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0227 20:32:07.110598 140629575182208 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b5\n","I0227 20:32:07.110808 140629575182208 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n","I0227 20:32:07.110875 140629575182208 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n","I0227 20:32:07.112958 140629575182208 efficientnet_model.py:144] round_filter input=32 output=48\n","I0227 20:32:07.131809 140629575182208 efficientnet_model.py:144] round_filter input=32 output=48\n","I0227 20:32:07.132019 140629575182208 efficientnet_model.py:144] round_filter input=16 output=24\n","I0227 20:32:07.351754 140629575182208 efficientnet_model.py:144] round_filter input=16 output=24\n","I0227 20:32:07.351982 140629575182208 efficientnet_model.py:144] round_filter input=24 output=40\n","I0227 20:32:07.821851 140629575182208 efficientnet_model.py:144] round_filter input=24 output=40\n","I0227 20:32:07.822082 140629575182208 efficientnet_model.py:144] round_filter input=40 output=64\n","I0227 20:32:08.293452 140629575182208 efficientnet_model.py:144] round_filter input=40 output=64\n","I0227 20:32:08.293664 140629575182208 efficientnet_model.py:144] round_filter input=80 output=128\n","I0227 20:32:08.958726 140629575182208 efficientnet_model.py:144] round_filter input=80 output=128\n","I0227 20:32:08.958941 140629575182208 efficientnet_model.py:144] round_filter input=112 output=176\n","I0227 20:32:09.641155 140629575182208 efficientnet_model.py:144] round_filter input=112 output=176\n","I0227 20:32:09.641369 140629575182208 efficientnet_model.py:144] round_filter input=192 output=304\n","I0227 20:32:10.558535 140629575182208 efficientnet_model.py:144] round_filter input=192 output=304\n","I0227 20:32:10.558757 140629575182208 efficientnet_model.py:144] round_filter input=320 output=512\n","I0227 20:32:10.876172 140629575182208 efficientnet_model.py:144] round_filter input=1280 output=2048\n","I0227 20:32:10.920522 140629575182208 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0227 20:32:11.026492 140629575182208 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b6\n","I0227 20:32:11.026689 140629575182208 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n","I0227 20:32:11.026760 140629575182208 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n","I0227 20:32:11.028707 140629575182208 efficientnet_model.py:144] round_filter input=32 output=56\n","I0227 20:32:11.047702 140629575182208 efficientnet_model.py:144] round_filter input=32 output=56\n","I0227 20:32:11.047919 140629575182208 efficientnet_model.py:144] round_filter input=16 output=32\n","I0227 20:32:11.268033 140629575182208 efficientnet_model.py:144] round_filter input=16 output=32\n","I0227 20:32:11.268238 140629575182208 efficientnet_model.py:144] round_filter input=24 output=40\n","I0227 20:32:11.827518 140629575182208 efficientnet_model.py:144] round_filter input=24 output=40\n","I0227 20:32:11.827712 140629575182208 efficientnet_model.py:144] round_filter input=40 output=72\n","I0227 20:32:12.408288 140629575182208 efficientnet_model.py:144] round_filter input=40 output=72\n","I0227 20:32:12.408524 140629575182208 efficientnet_model.py:144] round_filter input=80 output=144\n","I0227 20:32:13.199272 140629575182208 efficientnet_model.py:144] round_filter input=80 output=144\n","I0227 20:32:13.199487 140629575182208 efficientnet_model.py:144] round_filter input=112 output=200\n","I0227 20:32:14.365219 140629575182208 efficientnet_model.py:144] round_filter input=112 output=200\n","I0227 20:32:14.365423 140629575182208 efficientnet_model.py:144] round_filter input=192 output=344\n","I0227 20:32:15.472879 140629575182208 efficientnet_model.py:144] round_filter input=192 output=344\n","I0227 20:32:15.473106 140629575182208 efficientnet_model.py:144] round_filter input=320 output=576\n","I0227 20:32:15.797721 140629575182208 efficientnet_model.py:144] round_filter input=1280 output=2304\n","I0227 20:32:15.848961 140629575182208 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0227 20:32:15.974017 140629575182208 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b7\n","I0227 20:32:15.974211 140629575182208 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n","I0227 20:32:15.974275 140629575182208 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n","I0227 20:32:15.976258 140629575182208 efficientnet_model.py:144] round_filter input=32 output=64\n","I0227 20:32:15.994871 140629575182208 efficientnet_model.py:144] round_filter input=32 output=64\n","I0227 20:32:15.995076 140629575182208 efficientnet_model.py:144] round_filter input=16 output=32\n","I0227 20:32:16.298449 140629575182208 efficientnet_model.py:144] round_filter input=16 output=32\n","I0227 20:32:16.298660 140629575182208 efficientnet_model.py:144] round_filter input=24 output=48\n","I0227 20:32:16.961451 140629575182208 efficientnet_model.py:144] round_filter input=24 output=48\n","I0227 20:32:16.961656 140629575182208 efficientnet_model.py:144] round_filter input=40 output=80\n","I0227 20:32:17.643486 140629575182208 efficientnet_model.py:144] round_filter input=40 output=80\n","I0227 20:32:17.643689 140629575182208 efficientnet_model.py:144] round_filter input=80 output=160\n","I0227 20:32:18.592791 140629575182208 efficientnet_model.py:144] round_filter input=80 output=160\n","I0227 20:32:18.593024 140629575182208 efficientnet_model.py:144] round_filter input=112 output=224\n","I0227 20:32:19.561578 140629575182208 efficientnet_model.py:144] round_filter input=112 output=224\n","I0227 20:32:19.561789 140629575182208 efficientnet_model.py:144] round_filter input=192 output=384\n","I0227 20:32:20.909991 140629575182208 efficientnet_model.py:144] round_filter input=192 output=384\n","I0227 20:32:20.910207 140629575182208 efficientnet_model.py:144] round_filter input=320 output=640\n","I0227 20:32:21.676696 140629575182208 efficientnet_model.py:144] round_filter input=1280 output=2560\n","I0227 20:32:21.724206 140629575182208 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 27.73s\n","I0227 20:32:21.872537 140629575182208 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 27.73s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","I0227 20:32:21.880877 140629575182208 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","I0227 20:32:21.883101 140629575182208 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","I0227 20:32:21.883717 140629575182208 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","I0227 20:32:21.885512 140629575182208 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","[ RUN      ] ModelBuilderTF2Test.test_session\n","[  SKIPPED ] ModelBuilderTF2Test.test_session\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","I0227 20:32:21.887153 140629575182208 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","I0227 20:32:21.887674 140629575182208 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","I0227 20:32:21.888778 140629575182208 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","----------------------------------------------------------------------\n","Ran 24 tests in 32.646s\n","\n","OK (skipped=1)\n"]}],"source":["# From within TensorFlow/models/research/\n","#test if tensorflow downloaded successfully\n","!python object_detection/builders/model_builder_tf2_test.py"]},{"cell_type":"markdown","metadata":{"id":"MFvl3NAGNHCR"},"source":["## Import csv file, add needed columns and create a url_list "]},{"cell_type":"code","source":["cd /content/drive/MyDrive/Human_Detection_Tchibo"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cRM0k_f849Qb","executionInfo":{"status":"ok","timestamp":1645994453879,"user_tz":-60,"elapsed":183,"user":{"displayName":"Felix Steppack","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14866878991453271329"}},"outputId":"37e7d1eb-6c8e-48e0-d2ee-422bd94753cc"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Human_Detection_Tchibo\n"]}]},{"cell_type":"code","execution_count":10,"metadata":{"id":"9gXIO0afFg2-","executionInfo":{"status":"ok","timestamp":1645994457444,"user_tz":-60,"elapsed":183,"user":{"displayName":"Felix Steppack","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14866878991453271329"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"uyoRSP5nDEmu","executionInfo":{"status":"ok","timestamp":1645995560865,"user_tz":-60,"elapsed":199,"user":{"displayName":"Felix Steppack","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14866878991453271329"}}},"outputs":[],"source":["df_pics= pd.read_csv(\"tchibo_community_images.csv\", header = None, names=[\"image\", \"user\"] )"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":206,"status":"ok","timestamp":1645995561813,"user":{"displayName":"Felix Steppack","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14866878991453271329"},"user_tz":-60},"id":"U-UnPhd3DEp-","colab":{"base_uri":"https://localhost:8080/","height":206},"outputId":"4847aab5-07e2-4441-f88b-0850f470a83b"},"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-7333ebe8-3fa5-4256-b79b-8a12e7d912cb\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image</th>\n","      <th>user</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>https://assets-tch-live.s3.eu-central-1.amazon...</td>\n","      <td>d333f3791580c59e1fb803ced599da40</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>https://assets-tch-live.s3.eu-central-1.amazon...</td>\n","      <td>bc27b92c5a7625a04394e19fb6b53b5f</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>https://assets-tch-live.s3.eu-central-1.amazon...</td>\n","      <td>badc9b7866e336a9ae6e0db58f4ba7d1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>https://assets-tch-live.s3.eu-central-1.amazon...</td>\n","      <td>97c5f42c0eafe066300d47bddd0c14dc</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>https://assets-tch-live.s3.eu-central-1.amazon...</td>\n","      <td>47567a5f001ab3a178aebd9e58a352df</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7333ebe8-3fa5-4256-b79b-8a12e7d912cb')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7333ebe8-3fa5-4256-b79b-8a12e7d912cb button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7333ebe8-3fa5-4256-b79b-8a12e7d912cb');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                               image                              user\n","0  https://assets-tch-live.s3.eu-central-1.amazon...  d333f3791580c59e1fb803ced599da40\n","1  https://assets-tch-live.s3.eu-central-1.amazon...  bc27b92c5a7625a04394e19fb6b53b5f\n","2  https://assets-tch-live.s3.eu-central-1.amazon...  badc9b7866e336a9ae6e0db58f4ba7d1\n","3  https://assets-tch-live.s3.eu-central-1.amazon...  97c5f42c0eafe066300d47bddd0c14dc\n","4  https://assets-tch-live.s3.eu-central-1.amazon...  47567a5f001ab3a178aebd9e58a352df"]},"metadata":{},"execution_count":24}],"source":["df_pics.head()"]},{"cell_type":"code","source":["df_pics.user.value_counts()"],"metadata":{"id":"UcFSGdvPf5-9","executionInfo":{"status":"ok","timestamp":1645994464826,"user_tz":-60,"elapsed":184,"user":{"displayName":"Felix Steppack","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14866878991453271329"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"71a1f633-8efb-4bc4-bf87-f0bf863ca590"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2e95251e28153ff771579f7c2330368d    7\n","badc9b7866e336a9ae6e0db58f4ba7d1    5\n","6845c7f8c91ce1f985fecfc39a03c33a    5\n","67b21469e20c03ba49af6d78bffb46fc    5\n","e9773d68cc2975c1dfca9b9e9fa2a871    4\n","                                   ..\n","3076d12136e4a3a18271f7b13110f39c    1\n","2e95a3d662ed51e6a2aa7917419c0825    1\n","0be8cf3c99316e2284ac832681beeaf9    1\n","d2d589ab7b56c0cb5ce072821747fc7f    1\n","a086e4344da34ad99e90426d61827160    1\n","Name: user, Length: 299, dtype: int64"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","execution_count":14,"metadata":{"id":"gwzDIjK3DEss","executionInfo":{"status":"ok","timestamp":1645994467204,"user_tz":-60,"elapsed":192,"user":{"displayName":"Felix Steppack","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14866878991453271329"}}},"outputs":[],"source":["url_list= df_pics.image.tolist()"]},{"cell_type":"markdown","source":["--> hier können wir dann noch eine kleine explorative datenanalyse machen. wer postet am meisten Tchibofotos ... und wer welche mit hohen confidence score (gut zum Marketing verwenden) --> groupby..."],"metadata":{"id":"Zp1oRfrEkuzO"}},{"cell_type":"markdown","source":["##Load the model"],"metadata":{"id":"SJSZEZL3fgva"}},{"cell_type":"markdown","source":["If there are problems with cv2 (\"registerMatetype\" or something like that) run the cell below and restart runtime"],"metadata":{"id":"Zc5kfFbnPoNS"}},{"cell_type":"code","source":["#upgrade specific opencv liabaries to have all opencv libaries up to date\n","!pip uninstall opencv-python\n","!pip install opencv-python\n","!pip uninstall opencv-contrib-python\n","!pip install opencv-contrib-python\n","!pip uninstall opencv-python-headless\n","!pip install opencv-python-headless"],"metadata":{"id":"WRnZEzynYgif"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GTTgxTJVM97g"},"outputs":[],"source":["# load the model\n","import tensorflow as tf\n","import time\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as viz_utils\n","\n","path_to_saved_model = \"/content/drive/MyDrive/training_demo/new_exported_models/Exported_centernet_512_updated/saved_model\"\n","\n","print('Loading model...', end='')\n","start_time = time.time()\n","\n","# load saved model \n","detect_fn = tf.saved_model.load(path_to_saved_model)\n","\n","end_time = time.time()\n","elapsed_time = end_time - start_time\n","print('Done! Took {} seconds'.format(elapsed_time))"]},{"cell_type":"markdown","source":["## Predict each url and write the first detection class and belonging confidence score to dataframe with urls"],"metadata":{"id":"W16oSD2JfJ78"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"mPhBePCzMJd9"},"outputs":[],"source":["# LOAD LABEL MAP DATA FOR PLOTTING\n","# PROVIDE PATH TO LABEL MAp\n","\n","path_to_labels = '/content/drive/MyDrive/training_demo/annotations/label_map.pbtxt'\n","category_index = label_map_util.create_category_index_from_labelmap(path_to_labels,\n","                                                                    use_display_name=True)\n","#import all packages\n","import cv2 \n","from google.colab.patches import cv2_imshow                                                                   \n","import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import warnings\n","from skimage import io\n","warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n","\n","#define function reading image from url \n","def load_image_from_url(url):\n","  return io.imread(url)\n","\n","#define classification threshold. Determines which predictions are written to csv file\n","classification_threshold = 0.5\n","\n","\n","#iterate through url list and display each detection\n","i=0\n","for picture in url_list:\n","\n","  image= load_image_from_url(picture) #--> that does not work yet\n","  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","  #image_expanded = np.expand_dims(image_rgb, axis=0)\n","\n","  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n","  input_tensor = tf.convert_to_tensor(image)\n","  # The model expects a batch of images, so add an axis with `tf.newaxis`.\n","  input_tensor = input_tensor[tf.newaxis, ...]\n","\n","  # input_tensor = np.expand_dims(image_np, 0)\n","  detections = detect_fn(input_tensor)\n","\n","  # All outputs are batches tensors.\n","  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n","\n","\n","  num_detections = int(detections.pop('num_detections'))\n","  detections = {key: value[0, :num_detections].numpy()\n","                    for key, value in detections.items()}\n","\n","  detections['detection_classes'] = np.where(detections['detection_classes'] == 1, 'Tchibo Logo', 'Face')\n","\n","  n_detection = 0\n","  for detection in detections['detection_scores']:\n","    if detections['detection_scores'][n_detection] >= classification_threshold:\n","      df_pics.loc[df_pics['image'] == picture, 'detectionclass_' + str(n_detection)] = \\\n","      detections['detection_classes'][n_detection]\n","      df_pics.loc[df_pics['image'] == picture, 'detectionscore_' + str(n_detection)] = \\\n","      detections['detection_scores'][n_detection]\n","      '''\n","      #write the bounding box coordinates to csv file\n","      df_pics.loc[df_pics['image'] == picture, 'x_min_' + str(n_detection)] = \\\n","      detections['detection_boxes'][n_detection][0] * 1000\n","      df_pics.loc[df_pics['image'] == picture, 'y_min_' + str(n_detection)] = \\\n","      detections['detection_boxes'][n_detection][1] * 1000\n","      df_pics.loc[df_pics['image'] == picture, 'x_max_' + str(n_detection)] = \\\n","      detections['detection_boxes'][n_detection][2] * 1000\n","      df_pics.loc[df_pics['image'] == picture, 'y_max_' + str(n_detection)] = \\\n","      detections['detection_boxes'][n_detection][3] * 1000\n","      '''\n","      n_detection += 1\n","    else:\n","      n_detection += 1\n","\n"]},{"cell_type":"markdown","source":["Display the detection class and confidence scroe to compare to dataframe data. \n","Checks if data was written correctly to dataframe"],"metadata":{"id":"pCIoXexDe7AZ"}},{"cell_type":"code","source":["# LOAD LABEL MAP DATA FOR PLOTTING\n","# PROVIDE PATH TO LABEL MAP\n","path_to_labels = '/content/drive/MyDrive/training_demo/annotations/label_map.pbtxt'\n","category_index = label_map_util.create_category_index_from_labelmap(path_to_labels,\n","                                                                    use_display_name=True)\n","#import all packages\n","import cv2 \n","from google.colab.patches import cv2_imshow                                                                   \n","import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import warnings\n","from skimage import io\n","warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n","\n","#define function reading image from url \n","def load_image_from_url(url):\n","  return io.imread(url)\n","\n","#iterate through image path list and display each detection\n","i=0\n","for urls in url_list:\n","  if i >4:\n","    break\n","  i+=1\n","  image= load_image_from_url(urls) #--> that does not work yet\n","  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n","  input_tensor = tf.convert_to_tensor(image)\n","  # The model expects a batch of images, so add an axis with `tf.newaxis`.\n","  input_tensor = input_tensor[tf.newaxis, ...]\n","\n","  # input_tensor = np.expand_dims(image_np, 0)\n","  detections = detect_fn(input_tensor)\n","\n","  # All outputs are batches tensors.\n","  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n","  # We're only interested in the first num_detections.\n","  num_detections = int(detections.pop('num_detections'))\n","  detections = {key: value[0, :num_detections].numpy()\n","                for key, value in detections.items()}\n","  detections['num_detections'] = num_detections\n","\n","  # detection_classes should be ints.\n","  detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n","\n","  image_with_detections = image.copy()\n","\n","  # set min_score_thresh based on your minimum thrshold for detection \n","  viz_utils.visualize_boxes_and_labels_on_image_array(\n","        image_with_detections,\n","        detections['detection_boxes'],\n","        detections['detection_classes'],\n","        detections['detection_scores'],\n","        category_index,\n","        use_normalized_coordinates=True,\n","        max_boxes_to_draw=5,\n","        min_score_thresh=0.25,\n","        agnostic_mode=False)\n","\n","  # display output image \n","  cv2_imshow(image_with_detections)\n","  "],"metadata":{"id":"REdHbA6ZTTlz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_pics.head(20)"],"metadata":{"id":"RAzR8JR0dwBb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Write dataframe to csv and download csv"],"metadata":{"id":"mrJ8aedcjNY7"}},{"cell_type":"code","source":["df.to_csv(r\"/content/drive/MyDrive/training_demo/images/tcompics_labled.csv\", index=False)"],"metadata":{"id":"Buy_H_685Qhh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"FF3B0XCejQ96"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"TPU","colab":{"machine_shape":"hm","name":"4_Tchiboproject_predict_to_csv.ipynb","provenance":[],"collapsed_sections":["QixeQd1l_1ID"],"authorship_tag":"ABX9TyNkGZ3USQ5oUWmt3n7M5Tql"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}